{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Introduction**\n",
        "\n",
        "This project fine-tunes a pre-trained large language model (LLM), FLAN-T5, to build a medical chatbot capable of handling patient-doctor dialogues. Fine-tuning is done using Parameter Efficient Fine-Tuning (PEFT), particularly through Low-Rank Adaptation (LoRA) and QLoRA. This approach drastically reduces the number of trainable parameters and memory footprint while maintaining model performance. The results are evaluated using the ROUGE and BLEU metrics."
      ],
      "metadata": {
        "id": "zzM_TcZKlrX-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installations & Imports**\n"
      ],
      "metadata": {
        "id": "Lp0fjd2NmBqU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mat8Snx20A_",
        "outputId": "250191a3-dcf0-4b67-e492-ba7e28077b1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Sep  7 13:08:35 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   76C    P0              31W /  70W |  11501MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "#Displaying NVIDIA GPU Information using nvidia-smi Command\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhZZGMcY3JIr",
        "outputId": "99bf4063-5f8c-4a79-a390-583730fd3efc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.0+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# Installing PyTorch, TorchVision, and TorchAudio Libraries\n",
        "!pip3 install torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtTfiFT33Kpj",
        "outputId": "5b53e651-bc9e-41ac-ca1e-b078a941ced0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "#Installing and Upgrading BitsAndBytes, Transformers, PEFT, and Accelerate Libraries\n",
        "\n",
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndncqiy33Xx5",
        "outputId": "8fea9171-d7af-4178-830a-7f142cbb8d10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "# Upgrading and Installing the Datasets Library\n",
        "!pip install -U datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jmxAvYn3fkA",
        "outputId": "1308f420-bcf6-43bc-bc08-508b3332d05e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.2)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.21.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.24.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.15.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "#Installing the Evaluate Library\n",
        "%pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCJr2n913lO9"
      },
      "outputs": [],
      "source": [
        "# Installing and Upgrading the TRL (Transformers Reinforcement Learning) Library\n",
        "%pip -q install -U trl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jppNUbS-32PV"
      },
      "outputs": [],
      "source": [
        "# Installing Specific Versions of Rouge Score and Loralib Libraries\n",
        "%pip install \\\n",
        "    rouge_score==0.1.2 \\\n",
        "    loralib==0.1.1 --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-HzhIJN33L5"
      },
      "outputs": [],
      "source": [
        "# Importing Necessary Libraries for NLP, Model Training, and Evaluation\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, BitsAndBytesConfig, GenerationConfig, TrainingArguments, Trainer\n",
        "from peft import PeftModel, PeftConfig\n",
        "from datasets import load_dataset\n",
        "from trl import SFTTrainer, setup_chat_format\n",
        "\n",
        "import evaluate\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzOnXjJu375W",
        "outputId": "1bd85fd8-1990-4f60-a4f0-3b59e8ffe935"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "# Check if CUDA (GPU) is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data set information**\n",
        "\n",
        "The dataset is \"ruslanmv/ai-medical-chatbot\" from Hugging Face, which contains dialogues between patients and doctors. A subset of 1000 samples is selected to reduce processing time."
      ],
      "metadata": {
        "id": "0jSJQwT3pPGK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdL3MxcP4AYn"
      },
      "outputs": [],
      "source": [
        "# Loading and Preparing a Medical Chatbot Dataset for Model Training\n",
        "dataset_name = \"ruslanmv/ai-medical-chatbot\"\n",
        "dataset = load_dataset(dataset_name, split=\"all\")\n",
        "dataset = dataset.shuffle(seed=65).select(range(1000)) #Shuffling the dataset,Only using 1000 samples for quick demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGIkSYqU4BZi"
      },
      "outputs": [],
      "source": [
        "#Splitting the Dataset into Training and Test Sets (90% Training, 10% Testing)\n",
        "dataset = dataset.train_test_split(test_size=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVlcno0L4E-P",
        "outputId": "7b7171bf-f00c-497e-8d62-a664fe81fc06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['Description', 'Patient', 'Doctor'],\n",
              "        num_rows: 900\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['Description', 'Patient', 'Doctor'],\n",
              "        num_rows: 100\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "# splits the dataset into two subsets:Train and Test\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQe-iiZb4NMs"
      },
      "source": [
        "### 2.1 Samples from datasets\n",
        "\n",
        "The dataset has been divided into three parts\n",
        "\n",
        "\n",
        "*   Train\n",
        "*   Test\n",
        "*   Validation\n",
        "\n",
        "and can accessed by giving dict key value pairs. Some of the samples are as following\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnjEhzTp4SQu",
        "outputId": "7442ae88-e0ea-4ffd-d794-97be3389a70b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Randomly selected train Patient:\n",
            "I am 33 yrs old, had a hysterectomy at 32 years old (over a year ago) and it was a total hyst. I just went to the bathroom and my urine appeared to be of normal color however when I wiped there was pink on my toilet paper after wiping three times. The last time I had sex with my husband was approx. 3 days ago so I know he did not rip me or scratch anything (I normally tear). I have had a little cramping but nothing major. What could this be caused from? Could it be a bladder, kidney infection or a UTI or something else more so serious as they took my uterus and ovaries? Thanks!\n",
            "Randomly selected train Doctor:\n",
            "Helloyes it can be due to UTI though it most commonly causes BURNING SENSATION DURING MICTURITION...u should get a complete urine examination and ultrasound of kub region\n",
            "---------------------------------------------------------------------------------------------------\n",
            "\n",
            "Randomly selected test Patient:\n",
            "Sir, MY father used to have problems with his spine and had suffered.Then as he progressed and became better he started joging a lot on a hard surface in a hilly terrain.Now he has started to limp for a year has problems with his right hand as well.It cannot move and seems paralytical.Is is a neurological problem??\n",
            "Randomly selected test Doctor:\n",
            "hi welcome to hcm you need to do an MRI brain to rule out a paralysis problem if the MRI is clear then it might be because of the spine problem which can also be confirmed via MRI first find out the exact cause and then proceed because the treatment differs plus if he has associated urinary problems, problems with his sensation etc it might be a neuro case\n",
            "---------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Assuming you have three separate lists or arrays for train, test, and validation data\n",
        "train_data = dataset['train']\n",
        "test_data = dataset['test']\n",
        "\n",
        "# Generate random indices for each set\n",
        "train_index = random.randint(0, len(train_data) - 1)\n",
        "test_index = random.randint(0, len(test_data) - 1)\n",
        "\n",
        "# Retrieve dialogue and summary for the random indices\n",
        "random_train_dialogue = train_data[train_index]['Patient']\n",
        "random_train_summary = train_data[train_index]['Doctor']\n",
        "\n",
        "random_test_dialogue = test_data[test_index]['Patient']\n",
        "random_test_summary = test_data[test_index]['Doctor']\n",
        "\n",
        "# Print the results\n",
        "print(\"Randomly selected train Patient:\")\n",
        "print(random_train_dialogue)\n",
        "print(\"Randomly selected train Doctor:\")\n",
        "print(random_train_summary)\n",
        "\n",
        "print('-'.join('' for x in range(100)))\n",
        "\n",
        "print(\"\\nRandomly selected test Patient:\")\n",
        "print(random_test_dialogue)\n",
        "print(\"Randomly selected test Doctor:\")\n",
        "print(random_test_summary)\n",
        "\n",
        "print('-'.join('' for x in range(100)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y22_aC3h4b-0"
      },
      "source": [
        "### 2.2 - Preprocess the Dataset\n",
        "\n",
        "Formatting the dataset into **Prompt -- Response** pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRvV-1jj4YWD",
        "outputId": "e9f410bd-b0d7-4286-c72e-3a2002b4457d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1614: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#Specifying the Model Name for Fine-Tuning\n",
        "model_name='google/flan-t5-base'\n",
        "\n",
        "#Setting torch_dtype=torch.bfloat16 specifies the memory type to be used by this model\n",
        "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16).to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize_function(example):\n",
        "    \"\"\"Tokenizes the input and output text for a summarization example.\n",
        "\n",
        "    Args:\n",
        "        example (dict): A summarization example, with the following keys:\n",
        "            * dialogue (list): A list of strings, representing the conversation to be summarized.\n",
        "            * summary (str): The summary of the conversation.\n",
        "\n",
        "    Returns:\n",
        "        example (dict): The same example, with the following additional keys:\n",
        "            * input_ids (torch.Tensor): The tokenized input text.\n",
        "            * labels (torch.Tensor): The tokenized output text.\n",
        "    \"\"\"\n",
        "\n",
        "    start_prompt = 'User:\\n\\n'\n",
        "    end_prompt = '\\n\\nResponse: '\n",
        "    prompt = [start_prompt + dialogue + end_prompt for dialogue in example[\"Patient\"]]\n",
        "    example['input_ids'] = tokenizer(prompt, padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
        "    example['labels'] = tokenizer(example[\"Doctor\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\").input_ids\n",
        "\n",
        "    return example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "812a21b9343441b89d6ab67e181bd93a",
            "c0931e483c6c46e194ebe7c49edbecc1",
            "4bc0a5b14adf4e8a81e61c52767180c5",
            "577350bb500147278e374b696c9044d7",
            "72fb9787564c487d8f431111c4932a65",
            "2538f11b4a7e4fe3a5adc83ce5fa217b",
            "a980e8061d424540abbd72caaca94237",
            "fa16b17d3b144dfaad78f435fdba7ed6",
            "c9acd16cafa04d29991a206d869cd1b5",
            "f52a09594c034066aeb091a58a6b0ce2",
            "66e96f28554f495e95cefb87b1fbea0e",
            "1c429392c5b14006ba15bcbfc41a1417",
            "cc214dc925884a23922968ebc83d0e03",
            "be188b0bdf514a448560cd4556a3e1a7",
            "f81459c1833e49ac9025d3e6d7974dae",
            "aede15b57a574e38ae7c20b06a94114d",
            "1db8cd78d4f3416ca88a731990592d4f",
            "61dd99d028534060ad12c5ee16a2b7ef",
            "b0133227361740a29965d537c5783632",
            "b830e14e80fb4f9ca14ce8bea7844754",
            "a4c446dbf2e340d99b9f702d7408e381",
            "f08fbd454ccd43c28ed24b62d822adb1"
          ]
        },
        "id": "E4c4hxGO4m_B",
        "outputId": "583d59a2-4a9a-46c4-f988-5813ddda3b56"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/900 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "812a21b9343441b89d6ab67e181bd93a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c429392c5b14006ba15bcbfc41a1417"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# The dataset actually contains 3 diff splits: train, validation, test.\n",
        "# The tokenize_function code is handling all data across all splits in batches.\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "tokenized_datasets = tokenized_datasets.remove_columns(['Description', 'Patient', 'Doctor',])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPFavRUp4oOf",
        "outputId": "ebe11c96-9c3d-4c55-eb96-107dec24c2ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes of the datasets:\n",
            "Training: (900, 2)\n",
            "Test: (100, 2)\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['input_ids', 'labels'],\n",
            "        num_rows: 900\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['input_ids', 'labels'],\n",
            "        num_rows: 100\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print(f\"Shapes of the datasets:\")\n",
        "# print(f\"Training: {tokenized_datasets.shape}\")\n",
        "print(f\"Training: {tokenized_datasets['train'].shape}\")\n",
        "print(f\"Test: {tokenized_datasets['test'].shape}\")\n",
        "\n",
        "print(tokenized_datasets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OlF_Mml4vAg"
      },
      "source": [
        "## 3. Loading Pretrained LLM\n",
        "FLAN-T5: Pre-trained transformer model known for handling instruction-based tasks. It is loaded from Hugging Face in bfloat16 precision (a memory-efficient format).\n",
        "Load the pre-trained [FLAN-T5](https://huggingface.co/docs/transformers/model_doc/flan-t5) model and its tokenizer directly from HuggingFace. Notice that you will be using the base version of FLAN-T5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hhbTU9s4v4B"
      },
      "outputs": [],
      "source": [
        "model_name='google/flan-t5-base'\n",
        "\n",
        "#Setting torch_dtype=torch.bfloat16 specifies the memory type to be used by this model\n",
        "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16).to(device)\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qw9Zu_F43AS"
      },
      "source": [
        "## 4. Testing Model without Fine-Tuning\n",
        "\n",
        "Testing the base model without fine-tuning using some test examples from the dataset to define the baseline to which we'll compare the fine-tunined version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSaOFnLy408W"
      },
      "outputs": [],
      "source": [
        "# Accessing Test Dataset Samples\n",
        "Patient = dataset['test'][1]['Patient']\n",
        "response = dataset['test'][1]['Doctor']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AChGe4qu47jp",
        "outputId": "c164a304-bcfe-4412-95a5-5333363d8203"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected test Patient:\n",
            "I have a psoriasis scar on my face it ocassional flares I'm thinking of using ambi skin bleachCream to lighten it, I used to scratch it inn my sleep and I'm wondering if the skin bleaching cream will worsen it instead of lightening this embarrassing scar\n",
            "Selected test response:\n",
            "Hi there,Thanks for posting here.You appear to have a post inflammatory hyperpigmentation on face.Avoid bleaches as they may cause more damage.Use a good suscreen with SPF30 daily morning. you can use a mild skin lightening cream containing vitamin c and kojic acid at night.Take care.Hope this helps you.Regards,Dr Shilpa BhatM.D DermatologyBangalore\n"
          ]
        }
      ],
      "source": [
        "print(\"Selected test Patient:\")\n",
        "print(Patient)\n",
        "print(\"Selected test response:\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuaVvajp4_lL"
      },
      "outputs": [],
      "source": [
        "# Creating a prompt so that we can pass it to the model\n",
        "prompt = f\"\"\"\n",
        "Patient:\n",
        "\n",
        "{Patient}\n",
        "\n",
        "Response:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2gTNWBQ5BpW"
      },
      "outputs": [],
      "source": [
        "# Tokenize the input text using the tokenizer\n",
        "inputs = tokenizer(prompt, return_tensors='pt').to(device)\n",
        "\n",
        "# Generate text using the original model and store the prediction\n",
        "pred = original_model.generate(inputs[\"input_ids\"], max_new_tokens=200,)[0]\n",
        "\n",
        "# Decode the generated token IDs into human-readable text, skipping special tokens\n",
        "output = tokenizer.decode(pred, skip_special_tokens=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si6K8rkw5FXW",
        "outputId": "6064e28b-55f6-4ab1-9b9f-873468ff150b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "\n",
            "Patient:\n",
            "\n",
            "I have a psoriasis scar on my face it ocassional flares I'm thinking of using ambi skin bleachCream to lighten it, I used to scratch it inn my sleep and I'm wondering if the skin bleaching cream will worsen it instead of lightening this embarrassing scar\n",
            "\n",
            "Response:\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "BASELINE Doctor Response:\n",
            "Hi there,Thanks for posting here.You appear to have a post inflammatory hyperpigmentation on face.Avoid bleaches as they may cause more damage.Use a good suscreen with SPF30 daily morning. you can use a mild skin lightening cream containing vitamin c and kojic acid at night.Take care.Hope this helps you.Regards,Dr Shilpa BhatM.D DermatologyBangalore\n",
            "\n",
            "---------------------------------------------------------------------------------------------------\n",
            "MODEL GENERATION - ZERO SHOT:\n",
            "i.\n"
          ]
        }
      ],
      "source": [
        "# Results\n",
        "\n",
        "print('-'.join('' for x in range(100)))\n",
        "print(f'INPUT PROMPT:\\n{prompt}')\n",
        "print('-'.join('' for x in range(100)))\n",
        "print(f'BASELINE Doctor Response:\\n{response}\\n')\n",
        "print('-'.join('' for x in range(100)))\n",
        "print(f'MODEL GENERATION - ZERO SHOT:\\n{output}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "462NCyNJ5Nfk"
      },
      "source": [
        "### 4.1 Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcqJ_q7M5J9Y"
      },
      "outputs": [],
      "source": [
        "# Loading Evaluation Metrics for Model Performance\n",
        "rouge_metric = evaluate.load('rouge')\n",
        "bleu_metric = evaluate.load('bleu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehralCz95SzM"
      },
      "outputs": [],
      "source": [
        "# getting all 1000 values from the test dataset\n",
        "patient = dataset['test'][:1]['Patient']\n",
        "baseline_response = dataset['test'][:1]['Doctor']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErsgWpRJ5du4",
        "outputId": "17f52651-5321-4574-bb13-b004ba6059fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "len(patient), len(baseline_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6XOKVbt5fvp"
      },
      "outputs": [],
      "source": [
        "original_model_response = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sevcjFwk5h87",
        "outputId": "ba9e3532-0722-43da-d917-ee04736c2d54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing dialogues: 1it [00:02,  2.24s/it]\n"
          ]
        }
      ],
      "source": [
        "# Generating Model Responses for Patient Dialogues\n",
        "\n",
        "for i, x in tqdm(enumerate(patient), desc=\"Processing dialogues\"):\n",
        "    prompt = f\"\"\"\n",
        "                Patient:\n",
        "\n",
        "                {x}\n",
        "\n",
        "                Response:\n",
        "             \"\"\"\n",
        "\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
        "\n",
        "    original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200))\n",
        "    original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
        "    original_model_response.append(original_model_text_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "yAdU7NVz5mYj",
        "outputId": "1b609afe-668b-417b-9d99-82a856ae249d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             human_baseline_response  \\\n",
              "0  This is really  a funny thing..... what made h...   \n",
              "\n",
              "                             original_model_response  \n",
              "0  The patient is my younger brother who got marr...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc598ae2-d8ef-49ab-b394-cca9c141b712\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>human_baseline_response</th>\n",
              "      <th>original_model_response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This is really  a funny thing..... what made h...</td>\n",
              "      <td>The patient is my younger brother who got marr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc598ae2-d8ef-49ab-b394-cca9c141b712')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dc598ae2-d8ef-49ab-b394-cca9c141b712 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dc598ae2-d8ef-49ab-b394-cca9c141b712');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"human_baseline_response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"This is really\\u00a0 a funny thing..... what made him to reject her ? is he confustion in her originity ? please find out the problem, than some body will suggest what to do ? Dr Naveen Kumar M, The Apollo Clinic, J.P.Nagar,B'LORE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"original_model_response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"The patient is my younger brother who got married 6 months ago,both of them had a sexual intercourse once after their engagement,from then he refused to marry her and somehow the marriage got over.now still he is not beliving her.now he has applied for the divorce also on his own.but all our otherfamily members are not finding any fault at the girl.could you please advise Hypnotist availiable in Chennai whom we can meet and take the treatment or otherwise please advise\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "zipped_summaries = list(zip(baseline_response, original_model_response))\n",
        "\n",
        "df = pd.DataFrame(zipped_summaries, columns = ['human_baseline_response', 'original_model_response'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e70HKjg5qdt",
        "outputId": "564647cd-dfda-4c40-c896-02fe3576f296"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "len(original_model_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ko1nMPu5v2V"
      },
      "outputs": [],
      "source": [
        "# Compute the ROUGE metrics\n",
        "original_model_results = rouge_metric.compute(\n",
        "    predictions=original_model_response,\n",
        "    references=baseline_response[0:len(original_model_response)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Q6z_1cR5xmW",
        "outputId": "d3bf072b-62ed-4756-d956-69f1bea051ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORIGINAL MODEL ROUGE RESULTS:\n",
            "{'rouge1': 0.18461538461538463, 'rouge2': 0.0, 'rougeL': 0.13846153846153844, 'rougeLsum': 0.13846153846153844}\n"
          ]
        }
      ],
      "source": [
        "print('ORIGINAL MODEL ROUGE RESULTS:')\n",
        "print(original_model_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k96ojSJ150K1"
      },
      "outputs": [],
      "source": [
        "# original_model_results_scores = [x for _, x in original_model_results.items()]\n",
        "# labels = [x for x, _ in original_model_results.items()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "69Yfo3QZ54OS",
        "outputId": "d0049962-3cf7-4c4d-f31f-bb96307efe02"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Visualizing ROUGE Scores Comparison with Bar Graph\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "original_model_results_scores = [x for _, x in original_model_results.items()]\n",
        "labels = [x for x, _ in original_model_results.items()]\n",
        "\n",
        "# Bar width\n",
        "bar_width = 0.35\n",
        "\n",
        "# X-axis positions\n",
        "x = range(len(labels))\n",
        "\n",
        "# Create bar graph\n",
        "plt.bar(x, original_model_results_scores, width=bar_width,color = \"pink\", label='Original Model', align='center')\n",
        "\n",
        "# Labels and title\n",
        "plt.xlabel('ROUGE Metrics')\n",
        "plt.ylabel('Scores')\n",
        "plt.title('ROUGE Scores Comparison')\n",
        "\n",
        "# Fixing x-ticks\n",
        "plt.xticks(x, labels)\n",
        "plt.ylim(0, 0.25)\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQpbMfyG5-ZH"
      },
      "source": [
        "## 5. Parameter Efficient Fine-Tuning (PEFT)\n",
        "\n",
        "\n",
        "**PEFT** [Parameter-Efficient Fine-Tuning (PEFT) ](https://huggingface.co/docs/peft/index) is a technique to fine-tune LLMs with a small number of trainable parameters, making it computationally efficient. LoRA is one  technique that only updates certain matrices in the model rather than fine-tuning all parameters.\n",
        "\n",
        "**Low-rank adaptation (LoRA)**: LoRA is a technique that uses a low-rank matrix to encode the changes needed to fine-tune a pre-trained language model for a new task. LoRA is very efficient, as it only requires training a small number of parameters,\n",
        "while [QLoRA](https://github.com/artidoro/qlora) is an even more memory-efficient version of LoRA where the pre-trained model is loaded to GPU memory as quantized 4-bit weights (compared to 8-bits in the case of LoRA)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2MCyQ5u6FQR"
      },
      "source": [
        "### 5.1 Loading 4bit quantized model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-USzY_Y56ba"
      },
      "outputs": [],
      "source": [
        "model_name='google/flan-t5-base'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueQTwaJA6JzW"
      },
      "outputs": [],
      "source": [
        "# bnb_config = BitsAndBytesConfig(\n",
        "#     load_in_4bit=True,\n",
        "#     bnb_4bit_quant_type=\"nf4\",\n",
        "#     bnb_4bit_use_double_quant=True,\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-Me1x8o6LnP"
      },
      "outputs": [],
      "source": [
        "# Loading a Pretrained Seq2Seq Model with 4-bit Quantization and Mixed Precision\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "    pretrained_model_name_or_path=model_name,\n",
        "    device_map='auto',\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    quantization_config=BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_quant_type='nf4'\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FxHS3C76PRL",
        "outputId": "67fa48e3-37d0-46bc-9c70-bcddbcde448a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1614: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRp1uNWZ6TCF"
      },
      "outputs": [],
      "source": [
        "# Enabling Gradient Checkpointing and Preparing the Model for k-bit (Quantized) Training\n",
        "\n",
        "from peft import prepare_model_for_kbit_training\n",
        "\n",
        "model.gradient_checkpointing_enable()\n",
        "model = prepare_model_for_kbit_training(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a93RFpmF6X3x"
      },
      "source": [
        "### 5.2 - Setup the PEFT/LoRA model for Fine-Tuning\n",
        "\n",
        "The below code configures LoRA (Low-Rank Adaptation) for fine-tuning a sequence-to-sequence (Seq2Seq) model, such as FLAN-T5. LoRA is a technique that introduces low-rank decomposition to reduce the number of trainable parameters, making it more efficient to fine-tune large models on downstream tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGRu2oRG6UF-"
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=32, # Rank\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q\", \"v\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM # FLAN-T5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLVXi0C96b9F"
      },
      "outputs": [],
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhuQ53FH6eCF",
        "outputId": "32814f87-9f5a-43ea-b01b-d48f2073e197"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 3538944 || all params: 170900736 || trainable%: 2.070759952724838\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "peft_model = get_peft_model(model, lora_config)\n",
        "\n",
        "# peft_model = get_peft_model(original_model, lora_config)\n",
        "print(print_trainable_parameters(peft_model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tK68JHMQ6iP8"
      },
      "outputs": [],
      "source": [
        "output_dir = f'./peft-qlora-training-{str(int(time.time()))}'\n",
        "\n",
        "peft_training_args = TrainingArguments(\n",
        "        per_device_train_batch_size = 32,\n",
        "        warmup_steps=2,\n",
        "        num_train_epochs=2,\n",
        "        max_steps=500,\n",
        "        learning_rate=2e-4,\n",
        "        logging_steps=1,\n",
        "        output_dir=output_dir,\n",
        "        optim=\"paged_adamw_8bit\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqMvM0M4H5Cd",
        "outputId": "aa5012d3-1473-4436-9785-c5ca8f021788"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Run garbage collector\n",
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHG0OKlXH51I",
        "outputId": "c2a0dc0d-9617-4665-d096-226d2fb2d193"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        }
      ],
      "source": [
        "peft_trainer = Trainer(\n",
        "    model=peft_model,\n",
        "    args=peft_training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "D_pjIPENIDXS",
        "outputId": "2fec177a-5a32-436a-d174-c7b4fc8c2860"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 1:28:37, Epoch 17/18]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.137400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.020500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.084200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.094500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.008100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.013500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.916800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.913500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.967600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.974000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.655000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.729100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.577100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.690600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.585600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.927700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.668500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.624000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.608200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.673300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.608000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.548800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.451300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.527400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.454800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.436400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.710400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.603200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>1.910900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.417500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>1.610100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>1.330600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>1.880700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>1.287500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>1.545800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>1.458600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>1.439800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>1.587000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>1.635200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.208600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>1.334400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>1.304100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>1.383900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>1.289300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>1.164500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>1.256300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>1.370000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>1.210600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>1.309700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.118300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>1.243600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>1.515500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>1.267300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>1.410600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>1.317200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>1.211500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>1.219700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>2.521000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>1.341200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.259000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>1.197800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>1.405100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>1.344300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>1.204400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>1.169100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>1.162100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>1.042900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>1.320800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>1.432200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.152500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>1.286000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>1.267600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>1.157100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>1.442000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>1.189800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>1.107700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>1.319300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>1.132600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>1.192100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.093000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>1.274700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>1.347100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>1.249200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>1.088500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>1.254000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>1.247900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>0.718400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>1.314300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>0.839500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.041200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>1.180100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>1.172100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>1.271800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>1.224600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>1.116300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.911500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>1.183100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>1.307100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>1.091300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.060900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>101</td>\n",
              "      <td>1.152300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>102</td>\n",
              "      <td>1.159500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>103</td>\n",
              "      <td>1.173900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>104</td>\n",
              "      <td>1.357100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>1.258000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>106</td>\n",
              "      <td>1.198300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>107</td>\n",
              "      <td>1.330500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>108</td>\n",
              "      <td>1.218100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>109</td>\n",
              "      <td>0.960800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>1.344300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>111</td>\n",
              "      <td>1.300200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>112</td>\n",
              "      <td>1.064500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>113</td>\n",
              "      <td>1.193200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>114</td>\n",
              "      <td>1.032700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>1.076100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>116</td>\n",
              "      <td>0.931400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>117</td>\n",
              "      <td>1.010600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>118</td>\n",
              "      <td>1.216000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>119</td>\n",
              "      <td>1.337700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.042800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>121</td>\n",
              "      <td>0.984300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>122</td>\n",
              "      <td>1.002900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>123</td>\n",
              "      <td>1.056900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>124</td>\n",
              "      <td>1.124300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>1.180300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>126</td>\n",
              "      <td>1.280200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>127</td>\n",
              "      <td>1.180400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>128</td>\n",
              "      <td>1.209400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>129</td>\n",
              "      <td>1.038000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>1.111900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>131</td>\n",
              "      <td>1.167400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>132</td>\n",
              "      <td>1.064900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>133</td>\n",
              "      <td>1.120200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>134</td>\n",
              "      <td>1.090500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>135</td>\n",
              "      <td>1.061700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>136</td>\n",
              "      <td>1.123700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>137</td>\n",
              "      <td>1.195200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>138</td>\n",
              "      <td>1.071900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>139</td>\n",
              "      <td>0.924000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>1.032900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>141</td>\n",
              "      <td>1.200600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>142</td>\n",
              "      <td>1.201000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>143</td>\n",
              "      <td>1.038600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>144</td>\n",
              "      <td>1.204000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>145</td>\n",
              "      <td>1.478300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>146</td>\n",
              "      <td>1.345800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>147</td>\n",
              "      <td>1.103400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>148</td>\n",
              "      <td>1.027200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>149</td>\n",
              "      <td>1.120000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.186200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>151</td>\n",
              "      <td>1.002900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>152</td>\n",
              "      <td>1.051300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>153</td>\n",
              "      <td>1.086400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>154</td>\n",
              "      <td>1.105600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>155</td>\n",
              "      <td>1.004500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>156</td>\n",
              "      <td>1.099100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>157</td>\n",
              "      <td>1.150600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>158</td>\n",
              "      <td>1.014700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>159</td>\n",
              "      <td>0.988900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.947800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>161</td>\n",
              "      <td>1.115100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>162</td>\n",
              "      <td>1.241800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>163</td>\n",
              "      <td>1.015700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>164</td>\n",
              "      <td>1.210900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>165</td>\n",
              "      <td>0.981800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>166</td>\n",
              "      <td>0.957800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>167</td>\n",
              "      <td>1.016800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>168</td>\n",
              "      <td>0.874100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>169</td>\n",
              "      <td>1.141600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>1.139800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>171</td>\n",
              "      <td>1.143900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>172</td>\n",
              "      <td>1.287100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>173</td>\n",
              "      <td>1.125600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>174</td>\n",
              "      <td>1.014100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>0.991200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>176</td>\n",
              "      <td>0.997600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>177</td>\n",
              "      <td>1.151500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>178</td>\n",
              "      <td>1.085800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>179</td>\n",
              "      <td>1.133500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.972700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>181</td>\n",
              "      <td>1.214200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>182</td>\n",
              "      <td>1.032100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>183</td>\n",
              "      <td>1.092400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>184</td>\n",
              "      <td>1.065800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>185</td>\n",
              "      <td>1.110200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>186</td>\n",
              "      <td>1.164800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>187</td>\n",
              "      <td>1.008300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>188</td>\n",
              "      <td>0.915100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>189</td>\n",
              "      <td>1.099300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>1.226000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>191</td>\n",
              "      <td>1.051400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>192</td>\n",
              "      <td>1.041600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>193</td>\n",
              "      <td>0.994400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>194</td>\n",
              "      <td>1.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>195</td>\n",
              "      <td>1.027000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>196</td>\n",
              "      <td>1.314900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>197</td>\n",
              "      <td>0.979700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>198</td>\n",
              "      <td>1.130100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>199</td>\n",
              "      <td>1.026000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.001200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>201</td>\n",
              "      <td>1.137000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>202</td>\n",
              "      <td>0.947400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>203</td>\n",
              "      <td>1.173700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>204</td>\n",
              "      <td>0.941000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>205</td>\n",
              "      <td>1.005800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>206</td>\n",
              "      <td>1.291100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>207</td>\n",
              "      <td>0.961300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>208</td>\n",
              "      <td>1.057100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>209</td>\n",
              "      <td>1.119000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>1.132300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>211</td>\n",
              "      <td>1.160400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>212</td>\n",
              "      <td>1.139500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>213</td>\n",
              "      <td>1.004000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>214</td>\n",
              "      <td>0.931800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>215</td>\n",
              "      <td>0.879900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>216</td>\n",
              "      <td>0.996100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>217</td>\n",
              "      <td>1.077500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>218</td>\n",
              "      <td>1.184200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>219</td>\n",
              "      <td>1.041800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.894300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>221</td>\n",
              "      <td>1.069100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>222</td>\n",
              "      <td>1.291100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>223</td>\n",
              "      <td>1.201700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>224</td>\n",
              "      <td>0.963200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>1.007400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>226</td>\n",
              "      <td>0.996100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>227</td>\n",
              "      <td>0.947700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>228</td>\n",
              "      <td>1.001900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>229</td>\n",
              "      <td>1.101300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>1.061200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>231</td>\n",
              "      <td>1.025400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>232</td>\n",
              "      <td>0.966100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>233</td>\n",
              "      <td>1.051000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>234</td>\n",
              "      <td>1.135300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>235</td>\n",
              "      <td>1.011900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>236</td>\n",
              "      <td>1.040900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>237</td>\n",
              "      <td>0.994600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>238</td>\n",
              "      <td>1.111800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>239</td>\n",
              "      <td>1.230500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>1.098000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>241</td>\n",
              "      <td>1.034500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>242</td>\n",
              "      <td>1.318600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>243</td>\n",
              "      <td>0.972700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>244</td>\n",
              "      <td>0.958800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>245</td>\n",
              "      <td>1.011500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>246</td>\n",
              "      <td>1.060300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>247</td>\n",
              "      <td>0.874900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>248</td>\n",
              "      <td>1.037200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>249</td>\n",
              "      <td>0.911600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.931200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>251</td>\n",
              "      <td>1.010600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>252</td>\n",
              "      <td>1.123500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>253</td>\n",
              "      <td>1.069000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>254</td>\n",
              "      <td>1.060200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>255</td>\n",
              "      <td>0.953700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>256</td>\n",
              "      <td>1.083200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>257</td>\n",
              "      <td>0.922300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>258</td>\n",
              "      <td>1.025400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>259</td>\n",
              "      <td>1.216800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.858000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>261</td>\n",
              "      <td>1.093700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>262</td>\n",
              "      <td>1.041200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>263</td>\n",
              "      <td>1.102700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>264</td>\n",
              "      <td>1.141800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>265</td>\n",
              "      <td>1.012500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>266</td>\n",
              "      <td>0.978800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>267</td>\n",
              "      <td>0.812800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>268</td>\n",
              "      <td>1.080000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>269</td>\n",
              "      <td>0.951500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>1.117600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>271</td>\n",
              "      <td>1.155900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>272</td>\n",
              "      <td>1.055100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>273</td>\n",
              "      <td>1.075800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>274</td>\n",
              "      <td>0.931100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>0.922700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>276</td>\n",
              "      <td>1.130400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>277</td>\n",
              "      <td>0.979700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>278</td>\n",
              "      <td>1.029300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>279</td>\n",
              "      <td>0.990900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>1.115300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>281</td>\n",
              "      <td>1.222000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>282</td>\n",
              "      <td>1.142700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>283</td>\n",
              "      <td>0.982500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>284</td>\n",
              "      <td>1.119200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>285</td>\n",
              "      <td>0.886900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>286</td>\n",
              "      <td>0.983100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>287</td>\n",
              "      <td>0.891300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>288</td>\n",
              "      <td>0.783700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>289</td>\n",
              "      <td>1.092100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>1.518200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>291</td>\n",
              "      <td>0.997200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>292</td>\n",
              "      <td>1.074000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>293</td>\n",
              "      <td>1.084500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>294</td>\n",
              "      <td>0.917600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>295</td>\n",
              "      <td>1.140200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>296</td>\n",
              "      <td>0.916800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>297</td>\n",
              "      <td>1.087900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>298</td>\n",
              "      <td>1.080300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>299</td>\n",
              "      <td>1.055900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.311000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>301</td>\n",
              "      <td>0.885400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>302</td>\n",
              "      <td>1.116700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>303</td>\n",
              "      <td>0.837100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>304</td>\n",
              "      <td>1.056300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>305</td>\n",
              "      <td>1.107700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>306</td>\n",
              "      <td>1.038500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>307</td>\n",
              "      <td>1.022500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>308</td>\n",
              "      <td>0.935100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>309</td>\n",
              "      <td>1.155000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.888600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>311</td>\n",
              "      <td>1.060600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>312</td>\n",
              "      <td>0.856100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>313</td>\n",
              "      <td>0.842300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>314</td>\n",
              "      <td>0.965300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>315</td>\n",
              "      <td>0.956700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>316</td>\n",
              "      <td>0.997700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>317</td>\n",
              "      <td>0.938300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>318</td>\n",
              "      <td>1.282100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>319</td>\n",
              "      <td>1.053200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>1.142500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>321</td>\n",
              "      <td>0.974400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>322</td>\n",
              "      <td>1.044300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>323</td>\n",
              "      <td>0.909700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>324</td>\n",
              "      <td>1.127500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>1.108600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>326</td>\n",
              "      <td>1.006300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>327</td>\n",
              "      <td>1.080800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>328</td>\n",
              "      <td>0.955500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>329</td>\n",
              "      <td>0.883500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.976400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>331</td>\n",
              "      <td>1.024800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>332</td>\n",
              "      <td>1.007300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>333</td>\n",
              "      <td>1.045800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>334</td>\n",
              "      <td>0.973500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>335</td>\n",
              "      <td>0.886300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>336</td>\n",
              "      <td>0.900600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>337</td>\n",
              "      <td>0.891300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>338</td>\n",
              "      <td>1.099300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>339</td>\n",
              "      <td>1.246100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>1.056400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>341</td>\n",
              "      <td>1.021900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>342</td>\n",
              "      <td>0.901500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>343</td>\n",
              "      <td>1.140500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>344</td>\n",
              "      <td>0.837600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>345</td>\n",
              "      <td>0.966100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>346</td>\n",
              "      <td>1.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>347</td>\n",
              "      <td>1.009100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>348</td>\n",
              "      <td>1.340300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>349</td>\n",
              "      <td>1.168500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>1.135900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>351</td>\n",
              "      <td>0.882400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>352</td>\n",
              "      <td>0.947100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>353</td>\n",
              "      <td>0.944500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>354</td>\n",
              "      <td>1.012400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>355</td>\n",
              "      <td>1.039300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>356</td>\n",
              "      <td>1.109600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>357</td>\n",
              "      <td>0.941400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>358</td>\n",
              "      <td>1.110900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>359</td>\n",
              "      <td>1.003100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>1.112100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>361</td>\n",
              "      <td>0.947000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>362</td>\n",
              "      <td>1.121200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>363</td>\n",
              "      <td>0.964100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>364</td>\n",
              "      <td>0.959900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>365</td>\n",
              "      <td>0.913600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>366</td>\n",
              "      <td>1.023400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>367</td>\n",
              "      <td>1.036200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>368</td>\n",
              "      <td>1.098700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>369</td>\n",
              "      <td>1.039900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>1.045700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>371</td>\n",
              "      <td>0.975100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>372</td>\n",
              "      <td>0.827900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>373</td>\n",
              "      <td>0.872500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>374</td>\n",
              "      <td>0.867700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>0.945300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>376</td>\n",
              "      <td>1.055600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>377</td>\n",
              "      <td>1.810800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>378</td>\n",
              "      <td>0.799400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>379</td>\n",
              "      <td>0.992600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>1.053700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>381</td>\n",
              "      <td>1.195900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>382</td>\n",
              "      <td>1.128900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>383</td>\n",
              "      <td>0.791800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>384</td>\n",
              "      <td>1.005400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>385</td>\n",
              "      <td>0.887000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>386</td>\n",
              "      <td>1.035500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>387</td>\n",
              "      <td>0.942900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>388</td>\n",
              "      <td>1.075100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>389</td>\n",
              "      <td>0.983700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>1.129000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>391</td>\n",
              "      <td>1.062000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>392</td>\n",
              "      <td>1.157200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>393</td>\n",
              "      <td>1.041300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>394</td>\n",
              "      <td>1.158200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>395</td>\n",
              "      <td>0.955500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>396</td>\n",
              "      <td>1.037600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>397</td>\n",
              "      <td>0.967600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>398</td>\n",
              "      <td>1.081200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>399</td>\n",
              "      <td>0.852200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.889100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>401</td>\n",
              "      <td>0.990800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>402</td>\n",
              "      <td>0.857400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>403</td>\n",
              "      <td>0.948900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>404</td>\n",
              "      <td>0.982800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>405</td>\n",
              "      <td>1.078900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>406</td>\n",
              "      <td>0.856500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>407</td>\n",
              "      <td>0.976300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>408</td>\n",
              "      <td>0.882700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>409</td>\n",
              "      <td>1.158500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>410</td>\n",
              "      <td>0.967200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>411</td>\n",
              "      <td>0.896300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>412</td>\n",
              "      <td>0.994000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>413</td>\n",
              "      <td>0.941500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>414</td>\n",
              "      <td>0.839700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>415</td>\n",
              "      <td>0.931700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>416</td>\n",
              "      <td>0.853200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>417</td>\n",
              "      <td>0.942800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>418</td>\n",
              "      <td>1.016400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>419</td>\n",
              "      <td>0.970500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>420</td>\n",
              "      <td>0.931200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>421</td>\n",
              "      <td>1.118300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>422</td>\n",
              "      <td>1.138900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>423</td>\n",
              "      <td>1.023000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>424</td>\n",
              "      <td>0.972400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>1.032100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>426</td>\n",
              "      <td>0.980900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>427</td>\n",
              "      <td>1.062900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>428</td>\n",
              "      <td>0.979700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>429</td>\n",
              "      <td>1.166900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>430</td>\n",
              "      <td>1.135800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>431</td>\n",
              "      <td>1.060900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>432</td>\n",
              "      <td>1.049500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>433</td>\n",
              "      <td>1.038200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>434</td>\n",
              "      <td>0.869400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>435</td>\n",
              "      <td>1.277700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>436</td>\n",
              "      <td>0.991700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>437</td>\n",
              "      <td>0.935800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>438</td>\n",
              "      <td>0.947400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>439</td>\n",
              "      <td>1.093700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>440</td>\n",
              "      <td>1.066800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>441</td>\n",
              "      <td>1.002000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>442</td>\n",
              "      <td>1.017200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>443</td>\n",
              "      <td>1.041600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>444</td>\n",
              "      <td>0.933800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>445</td>\n",
              "      <td>1.064200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>446</td>\n",
              "      <td>1.168800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>447</td>\n",
              "      <td>1.000100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>448</td>\n",
              "      <td>0.960200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>449</td>\n",
              "      <td>0.831100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>1.042500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>451</td>\n",
              "      <td>0.892900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>452</td>\n",
              "      <td>1.054700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>453</td>\n",
              "      <td>1.030500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>454</td>\n",
              "      <td>0.886600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>455</td>\n",
              "      <td>1.169900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>456</td>\n",
              "      <td>1.117700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>457</td>\n",
              "      <td>1.003100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>458</td>\n",
              "      <td>1.038900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>459</td>\n",
              "      <td>0.844300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>460</td>\n",
              "      <td>0.913400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>461</td>\n",
              "      <td>0.897500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>462</td>\n",
              "      <td>0.925000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>463</td>\n",
              "      <td>1.102400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>464</td>\n",
              "      <td>1.144300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>465</td>\n",
              "      <td>1.138100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>466</td>\n",
              "      <td>0.862000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>467</td>\n",
              "      <td>0.994800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>468</td>\n",
              "      <td>0.968700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>469</td>\n",
              "      <td>0.931900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>470</td>\n",
              "      <td>0.989500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>471</td>\n",
              "      <td>1.119000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>472</td>\n",
              "      <td>0.971100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>473</td>\n",
              "      <td>0.937700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>474</td>\n",
              "      <td>0.777900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>475</td>\n",
              "      <td>1.018500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>476</td>\n",
              "      <td>1.061700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>477</td>\n",
              "      <td>0.922600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>478</td>\n",
              "      <td>1.234900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>479</td>\n",
              "      <td>1.086700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.771800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>481</td>\n",
              "      <td>0.911100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>482</td>\n",
              "      <td>0.985400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>483</td>\n",
              "      <td>1.048800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>484</td>\n",
              "      <td>0.967800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>485</td>\n",
              "      <td>0.786200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>486</td>\n",
              "      <td>0.971800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>487</td>\n",
              "      <td>1.019100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>488</td>\n",
              "      <td>1.145800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>489</td>\n",
              "      <td>1.176900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>490</td>\n",
              "      <td>1.044100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>491</td>\n",
              "      <td>0.936800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>492</td>\n",
              "      <td>1.060500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>493</td>\n",
              "      <td>1.179200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>494</td>\n",
              "      <td>0.947800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>495</td>\n",
              "      <td>0.975100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>496</td>\n",
              "      <td>1.143700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>497</td>\n",
              "      <td>1.024000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>498</td>\n",
              "      <td>1.124500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>499</td>\n",
              "      <td>1.045100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.892900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./peft-qlora-checkpoint-local/tokenizer_config.json',\n",
              " './peft-qlora-checkpoint-local/special_tokens_map.json',\n",
              " './peft-qlora-checkpoint-local/spiece.model',\n",
              " './peft-qlora-checkpoint-local/added_tokens.json',\n",
              " './peft-qlora-checkpoint-local/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "# Training the Model and Saving the Fine-Tuned Model and Tokenizer\n",
        "peft_trainer.train()\n",
        "\n",
        "peft_model_path=\"./peft-qlora-checkpoint-local\"\n",
        "\n",
        "peft_trainer.model.save_pretrained(peft_model_path)\n",
        "tokenizer.save_pretrained(peft_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ilUdc1VoMemp",
        "outputId": "7bfa7f85-3fbe-4a24-830c-2e371df0ffff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./peft-qlora-checkpoint-local'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "peft_model_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "iQXoMFGFM4Ro",
        "outputId": "6a01fc80-5784-4ec6-bdbb-7001f7d0f7b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/peft_model.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "# Define the name of the output zip file\n",
        "zip_file_name = \"peft_model.zip\"\n",
        "\n",
        "# Create a zip file\n",
        "shutil.make_archive(zip_file_name.replace('.zip', ''), 'zip', peft_model_path)\n",
        "\n",
        "# Move the zip file to the Colab's download directory\n",
        "shutil.move(zip_file_name.replace('.zip', '') + '.zip', '/content/' + zip_file_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "H-ZQb-FGM669",
        "outputId": "3b781981-77e0-4f28-89f2-d4f069a5a5aa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a530963b-4bf5-4e66-bb2c-8566ef4501e8\", \"peft_model.zip\", 14164560)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Provide a download link for the zip file\n",
        "from google.colab import files\n",
        "files.download(zip_file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ngT6mWoM_VR"
      },
      "outputs": [],
      "source": [
        "peft_model = '/content/peft-qlora-checkpoint-local'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5_QFxyANGUh",
        "outputId": "0d46d761-6a5d-483e-b624-20c704bd27ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1614: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from peft import PeftModel, PeftConfig\n",
        "\n",
        "model_base = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\", torch_dtype=torch.bfloat16)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
        "\n",
        "#Combining the adapter and model\n",
        "peft_model = PeftModel.from_pretrained(model_base, #base model\n",
        "                                       peft_model, #PEFT Adaptor\n",
        "                                       torch_dtype=torch.bfloat16,\n",
        "                                       is_trainable=False).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ItNtZyYNIS_",
        "outputId": "05a86f07-2dea-4b42-cbba-de3c5797c61f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 0 || all params: 251116800 || trainable%: 0.0\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(print_trainable_parameters(peft_model))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwrQxvCsNMu3"
      },
      "outputs": [],
      "source": [
        "# getting all 1000 values from the test dataset\n",
        "patient = dataset['test'][:1]['Patient']\n",
        "baseline_response = dataset['test'][:1]['Doctor']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVHAy8ZDNOsg"
      },
      "outputs": [],
      "source": [
        "finetuned_model_response = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvhwwBlONQxL",
        "outputId": "65eeabce-ad2c-45d1-f87b-2a7e9e8dedd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing dialogues: 1it [00:00,  1.52it/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#Generating and Collecting Responses from the Fine-Tuned PEFT Model\n",
        "\n",
        "for i, x in tqdm(enumerate(patient), desc=\"Processing dialogues\"):\n",
        "    prompt = f\"\"\"\n",
        "                Patient:\n",
        "\n",
        "                {x}\n",
        "\n",
        "                Response:\n",
        "             \"\"\"\n",
        "\n",
        "\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
        "\n",
        "    # original_model_outputs = original_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
        "    # original_model_text_output = tokenizer.decode(original_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    peft_model_outputs = peft_model.generate(input_ids=input_ids, generation_config=GenerationConfig(max_new_tokens=200, num_beams=1))\n",
        "    peft_model_text_output = tokenizer.decode(peft_model_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # original_model_response.append(original_model_text_output)\n",
        "    finetuned_model_response.append(peft_model_text_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "bzk6pnisNUZP",
        "outputId": "67de4127-eb8f-44d4-a0dc-667cc144a377"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             human_baseline_response  \\\n",
              "0  This is really  a funny thing..... what made h...   \n",
              "\n",
              "                             original_model_response  \\\n",
              "0  The patient is my younger brother who got marr...   \n",
              "\n",
              "                            finetuned_model_response  \n",
              "0  Hypnotist available in Chennai who can help yo...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5db38a27-6c84-47eb-aeb9-21bce7aef612\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>human_baseline_response</th>\n",
              "      <th>original_model_response</th>\n",
              "      <th>finetuned_model_response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This is really  a funny thing..... what made h...</td>\n",
              "      <td>The patient is my younger brother who got marr...</td>\n",
              "      <td>Hypnotist available in Chennai who can help yo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5db38a27-6c84-47eb-aeb9-21bce7aef612')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5db38a27-6c84-47eb-aeb9-21bce7aef612 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5db38a27-6c84-47eb-aeb9-21bce7aef612');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"human_baseline_response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"This is really\\u00a0 a funny thing..... what made him to reject her ? is he confustion in her originity ? please find out the problem, than some body will suggest what to do ? Dr Naveen Kumar M, The Apollo Clinic, J.P.Nagar,B'LORE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"original_model_response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"The patient is my younger brother who got married 6 months ago,both of them had a sexual intercourse once after their engagement,from then he refused to marry her and somehow the marriage got over.now still he is not beliving her.now he has applied for the divorce also on his own.but all our otherfamily members are not finding any fault at the girl.could you please advise Hypnotist availiable in Chennai whom we can meet and take the treatment or otherwise please advise\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"finetuned_model_response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Hypnotist available in Chennai who can help you in a psychiatric treatment.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 110
        }
      ],
      "source": [
        "# Creating a DataFrame to Compare Human, Original Model, and Fine-Tuned Model Responses\n",
        "\n",
        "zipped_summaries = list(zip(baseline_response, original_model_response, finetuned_model_response))\n",
        "\n",
        "df = pd.DataFrame(zipped_summaries, columns = ['human_baseline_response', 'original_model_response', 'finetuned_model_response'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lXrXHOcNWkr"
      },
      "outputs": [],
      "source": [
        "# Compute the ROUGE metrics for Fine-Tuned Model Evaluation\n",
        "fine_tuned_model_results = rouge_metric.compute(\n",
        "    predictions=finetuned_model_response,\n",
        "    references=baseline_response[0:len(finetuned_model_response)],\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSZa6G8HNbp6",
        "outputId": "99dafd95-2c04-4267-d154-ceb0b7920a17"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'rouge1': 0.07272727272727272,\n",
              " 'rouge2': 0.0,\n",
              " 'rougeL': 0.03636363636363636,\n",
              " 'rougeLsum': 0.03636363636363636}"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ],
      "source": [
        "fine_tuned_model_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "X3ZhyvSyNgVG",
        "outputId": "f0e1b382-f5ca-4d15-915d-6debc959e228"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "# Plotting ROUGE Scores for the Fine-Tuned Model\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fine_tuned_model_results_scores = [x for _, x in fine_tuned_model_results.items()]\n",
        "labels = [x for x, _ in original_model_results.items()]\n",
        "\n",
        "# Bar width\n",
        "bar_width = 0.35\n",
        "\n",
        "# X-axis positions\n",
        "x = range(len(labels))\n",
        "\n",
        "# Create bar graph\n",
        "plt.bar(x, fine_tuned_model_results_scores, width=bar_width,color =\"teal\", label='Fine tuned Model', align='center')\n",
        "\n",
        "# Labels and title\n",
        "plt.xlabel('ROUGE Metrics')\n",
        "plt.ylabel('Scores')\n",
        "plt.title('ROUGE Scores Comparison')\n",
        "\n",
        "# Fixing x-ticks\n",
        "plt.xticks(x, labels)\n",
        "plt.ylim(0, 0.10)\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "Frp39kisNhWv",
        "outputId": "8872fd77-bd94-4640-f3d4-d145ba0d555d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Comparing ROUGE Scores: Original Model vs. Fine-Tuned Model\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Original and fine-tuned model results\n",
        "original_model_results_scores = [x for _, x in original_model_results.items()]\n",
        "fine_tuned_model_results_scores = [x for _, x in fine_tuned_model_results.items()]\n",
        "labels = [x for x, _ in original_model_results.items()]\n",
        "\n",
        "# Bar width\n",
        "bar_width = 0.35\n",
        "\n",
        "# X-axis positions for original model bars\n",
        "x = range(len(labels))\n",
        "\n",
        "# X-axis positions for fine-tuned model bars\n",
        "x_fine_tuned = [pos + bar_width for pos in x]\n",
        "\n",
        "# Create bar graphs for both models\n",
        "plt.bar(x, original_model_results_scores, width=bar_width,color=\"yellow\", label='Original Model', align='center')\n",
        "plt.bar(x_fine_tuned, fine_tuned_model_results_scores, width=bar_width,color=\"teal\", label='Fine-Tuned Model', align='center')\n",
        "\n",
        "# Labels and title\n",
        "plt.xlabel('ROUGE Metrics')\n",
        "plt.ylabel('Scores')\n",
        "plt.title('ROUGE Scores Comparison')\n",
        "\n",
        "# Fixing x-ticks\n",
        "plt.xticks([pos + bar_width / 2 for pos in x], labels)\n",
        "plt.ylim(0, 0.25)\n",
        "\n",
        "# Add legend\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "812a21b9343441b89d6ab67e181bd93a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0931e483c6c46e194ebe7c49edbecc1",
              "IPY_MODEL_4bc0a5b14adf4e8a81e61c52767180c5",
              "IPY_MODEL_577350bb500147278e374b696c9044d7"
            ],
            "layout": "IPY_MODEL_72fb9787564c487d8f431111c4932a65"
          }
        },
        "c0931e483c6c46e194ebe7c49edbecc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2538f11b4a7e4fe3a5adc83ce5fa217b",
            "placeholder": "​",
            "style": "IPY_MODEL_a980e8061d424540abbd72caaca94237",
            "value": "Map: 100%"
          }
        },
        "4bc0a5b14adf4e8a81e61c52767180c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa16b17d3b144dfaad78f435fdba7ed6",
            "max": 900,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9acd16cafa04d29991a206d869cd1b5",
            "value": 900
          }
        },
        "577350bb500147278e374b696c9044d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f52a09594c034066aeb091a58a6b0ce2",
            "placeholder": "​",
            "style": "IPY_MODEL_66e96f28554f495e95cefb87b1fbea0e",
            "value": " 900/900 [00:01&lt;00:00, 596.16 examples/s]"
          }
        },
        "72fb9787564c487d8f431111c4932a65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2538f11b4a7e4fe3a5adc83ce5fa217b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a980e8061d424540abbd72caaca94237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa16b17d3b144dfaad78f435fdba7ed6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9acd16cafa04d29991a206d869cd1b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f52a09594c034066aeb091a58a6b0ce2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66e96f28554f495e95cefb87b1fbea0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c429392c5b14006ba15bcbfc41a1417": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc214dc925884a23922968ebc83d0e03",
              "IPY_MODEL_be188b0bdf514a448560cd4556a3e1a7",
              "IPY_MODEL_f81459c1833e49ac9025d3e6d7974dae"
            ],
            "layout": "IPY_MODEL_aede15b57a574e38ae7c20b06a94114d"
          }
        },
        "cc214dc925884a23922968ebc83d0e03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1db8cd78d4f3416ca88a731990592d4f",
            "placeholder": "​",
            "style": "IPY_MODEL_61dd99d028534060ad12c5ee16a2b7ef",
            "value": "Map: 100%"
          }
        },
        "be188b0bdf514a448560cd4556a3e1a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0133227361740a29965d537c5783632",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b830e14e80fb4f9ca14ce8bea7844754",
            "value": 100
          }
        },
        "f81459c1833e49ac9025d3e6d7974dae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4c446dbf2e340d99b9f702d7408e381",
            "placeholder": "​",
            "style": "IPY_MODEL_f08fbd454ccd43c28ed24b62d822adb1",
            "value": " 100/100 [00:00&lt;00:00, 783.78 examples/s]"
          }
        },
        "aede15b57a574e38ae7c20b06a94114d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1db8cd78d4f3416ca88a731990592d4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61dd99d028534060ad12c5ee16a2b7ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0133227361740a29965d537c5783632": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b830e14e80fb4f9ca14ce8bea7844754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4c446dbf2e340d99b9f702d7408e381": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f08fbd454ccd43c28ed24b62d822adb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}